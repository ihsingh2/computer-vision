{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Blocks of ResNet18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import wandb\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models import resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = 'cv-s25-a2-resnet18'\n",
    "BATCH_SIZE = 64\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationMeasures:\n",
    "    \"\"\" Computes common evaluation measures for classification based tasks. \"\"\"\n",
    "\n",
    "    def __init__(self, y_true, y_pred):\n",
    "        \"\"\" Initializes the class to compute on given data.\n",
    "\n",
    "        Args:\n",
    "            y_true: Array containing true values.\n",
    "            y_pred: Array containing predicted values.\n",
    "        \"\"\"\n",
    "\n",
    "        # Store the passed arguments\n",
    "        self.y_true = y_true\n",
    "        self.y_pred = y_pred\n",
    "\n",
    "        # Initialize the classes based on y values\n",
    "        self.classes = np.unique(np.concatenate((y_true, y_pred)))\n",
    "        self.num_classes = self.classes.shape[0]\n",
    "\n",
    "        # Initialize the confusion matrices to None\n",
    "        self.confusion_matrices = None\n",
    "\n",
    "    def accuracy_score(self):\n",
    "        \"\"\" Computes the accuracy. \"\"\"\n",
    "\n",
    "        return np.mean(self.y_true == self.y_pred)\n",
    "\n",
    "    def _compute_confusion_matrices(self):\n",
    "        \"\"\" Computes the confusion matrices for each class. \"\"\"\n",
    "\n",
    "        confusion_matrices = np.empty((self.num_classes, 2, 2))\n",
    "\n",
    "        # Fill the confusion matrix for each classes\n",
    "        for idx, clx in enumerate(self.classes):\n",
    "            # True positive\n",
    "            confusion_matrices[idx, 0, 0] = np.sum((self.y_true == clx) & (self.y_pred == clx))\n",
    "            # False positive\n",
    "            confusion_matrices[idx, 0, 1] = np.sum((self.y_true != clx) & (self.y_pred == clx))\n",
    "            # False negative\n",
    "            confusion_matrices[idx, 1, 0] = np.sum((self.y_true == clx) & (self.y_pred != clx))\n",
    "            # True negative\n",
    "            confusion_matrices[idx, 1, 1] = np.sum((self.y_true != clx) & (self.y_pred != clx))\n",
    "\n",
    "        return confusion_matrices\n",
    "\n",
    "    def confusion_matrix(self):\n",
    "        \"\"\" Computes the overall confusion matrix. \"\"\"\n",
    "\n",
    "        confusion_matrix = np.zeros((self.num_classes, self.num_classes), dtype=int)\n",
    "\n",
    "        for true_idx, pred_idx in zip(self.y_true, self.y_pred):\n",
    "            confusion_matrix[true_idx, pred_idx] += 1\n",
    "\n",
    "        return confusion_matrix\n",
    "\n",
    "    def f1_score(self, average: Literal['micro', 'macro']):\n",
    "        \"\"\" Computes the f1 score. \"\"\"\n",
    "\n",
    "        # Validate the passed arguments\n",
    "        assert average in ['micro', 'macro'], f'Unrecognized argument for average {average}'\n",
    "\n",
    "        # Compute recall and precision with same method\n",
    "        recall = self.recall_score(average)\n",
    "        precision = self.precision_score(average)\n",
    "\n",
    "        # Compute the F1 score\n",
    "        f1 = 2 * recall * precision / (recall + precision)\n",
    "        return f1\n",
    "\n",
    "    def recall_score(self, average: Literal['micro', 'macro']):\n",
    "        \"\"\" Computes the recall. \"\"\"\n",
    "\n",
    "        # Validate the passed arguments\n",
    "        assert average in ['micro', 'macro'], f'Unrecognized argument for average {average}'\n",
    "\n",
    "        # Compute confusion matrix for each class\n",
    "        if self.confusion_matrices is None:\n",
    "            self.confusion_matrices = self._compute_confusion_matrices()\n",
    "\n",
    "        if average == 'micro':\n",
    "            # Compute recall of pooled confusion matrix\n",
    "            pooled_confusion_matrix = np.sum(self.confusion_matrices, axis=0)\n",
    "            recall = pooled_confusion_matrix[0, 0] / \\\n",
    "                            (pooled_confusion_matrix[0, 0] + pooled_confusion_matrix[0, 1])\n",
    "\n",
    "        elif average == 'macro':\n",
    "            # Compute average over recall of individual classes\n",
    "            recall = 0\n",
    "            for idx in range(self.num_classes):\n",
    "                denom = self.confusion_matrices[idx, 0, 0] + self.confusion_matrices[idx, 0, 1]\n",
    "                if denom != 0:\n",
    "                    recall += (self.confusion_matrices[idx, 0, 0] / denom)\n",
    "                else:\n",
    "                    recall += 1\n",
    "            recall /= self.num_classes\n",
    "\n",
    "        return recall\n",
    "\n",
    "    def precision_score(self, average: Literal['micro', 'macro']):\n",
    "        \"\"\" Computes the precision. \"\"\"\n",
    "\n",
    "        # Validate the passed arguments\n",
    "        assert average in ['micro', 'macro'], f'Unrecognized argument for average {average}'\n",
    "\n",
    "        # Compute confusion matrix for each class\n",
    "        if self.confusion_matrices is None:\n",
    "            self.confusion_matrices = self._compute_confusion_matrices()\n",
    "\n",
    "        if average == 'micro':\n",
    "            # Compute precision of pooled confusion matrix\n",
    "            pooled_confusion_matrix = np.sum(self.confusion_matrices, axis=0)\n",
    "            precision = pooled_confusion_matrix[0, 0] / \\\n",
    "                                (pooled_confusion_matrix[0, 0] + pooled_confusion_matrix[1, 0])\n",
    "\n",
    "        elif average == 'macro':\n",
    "            # Compute average over precision of individual classes\n",
    "            precision = 0\n",
    "            for idx in range(self.num_classes):\n",
    "                denom = self.confusion_matrices[idx, 0, 0] + self.confusion_matrices[idx, 1, 0]\n",
    "                if denom != 0:\n",
    "                    precision += (self.confusion_matrices[idx, 0, 0] / denom)\n",
    "                else:\n",
    "                    precision += 1\n",
    "            precision /= self.num_classes\n",
    "\n",
    "        return precision\n",
    "\n",
    "    def print_all_measures(self):\n",
    "        \"\"\" Evaluates and prints all the measures. \"\"\"\n",
    "\n",
    "        print('Accuracy:', self.accuracy_score())\n",
    "        print('Precision (Micro):', self.precision_score(average='micro'))\n",
    "        print('Recall (Micro):', self.recall_score(average='micro'))\n",
    "        print('F1 Score (Micro):', self.f1_score(average='micro'))\n",
    "        print('Precision (Macro):', self.precision_score(average='macro'))\n",
    "        print('Recall (Macro):', self.recall_score(average='macro'))\n",
    "        print('F1 Score (Macro):', self.f1_score(average='macro'))\n",
    "\n",
    "def train_model(model, train_loader, test_loader, model_name, epochs=10, lr=0.001):\n",
    "\n",
    "    wandb.init(project=PROJECT_NAME, name=model_name, reinit=True)\n",
    "\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct, total = 0, 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        train_acc = 100 * correct / total\n",
    "        test_acc = evaluate_model(model, test_loader)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: Loss: {running_loss:.4f}, Train Acc: {train_acc:.2f}%, Test Acc: {test_acc:.2f}%\")\n",
    "        wandb.log({\"Loss\": running_loss, \"Train Accuracy\": train_acc, \"Test Accuracy\": test_acc})\n",
    "\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = outputs.max(1)\n",
    "            y_true.append(labels)\n",
    "            y_pred.append(predicted)\n",
    "    y_true = torch.hstack(y_true).cpu().numpy()\n",
    "    y_pred = torch.hstack(y_pred).cpu().numpy()\n",
    "\n",
    "    f1_score = ClassificationMeasures(y_true, y_pred).f1_score(average='macro')\n",
    "    confusion_matrix = wandb.plot.confusion_matrix(y_true=y_true, preds=y_pred)\n",
    "    wandb.log({\"F1 Score\": f1_score, \"Confusion Matrix\": confusion_matrix})\n",
    "\n",
    "    wandb.finish()\n",
    "    model = model.to('cpu')\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels, transform=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.data[idx].float()\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "train_data = torch.load(\"../data/q1/train_data.pt\")\n",
    "train_labels = torch.load(\"../data/q1/train_labels.pt\")\n",
    "\n",
    "test_data = torch.load(\"../data/q1/test_data.pt\")\n",
    "test_labels = torch.load(\"../data/q1/test_labels.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Baseline - Training ResNet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation((-7,7)),\n",
    "    transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),\n",
    "    transforms.Normalize((0.491, 0.482, 0.446), (0.247, 0.243, 0.261)),\n",
    "])\n",
    "test_transform = transforms.Normalize((0.491, 0.482, 0.446), (0.247, 0.243, 0.261))\n",
    "\n",
    "train_dataset = CustomDataset(train_data, train_labels, transform=train_transform)\n",
    "test_dataset = CustomDataset(test_data, test_labels, transform=test_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet18(num_classes=10)\n",
    "train_model(model, train_loader, test_loader, 'scratch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = resnet18(weights='DEFAULT')\n",
    "pretrained_model.fc = nn.Linear(512, 10)\n",
    "train_model(pretrained_model, train_loader, test_loader, 'pretrained')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"train_loss_1.png\" alt=\"Train Loss\" width=\"450\"/>\n",
    "<img src=\"train_acc_1.png\" alt=\"Train Acc\" width=\"450\"/>\n",
    "<img src=\"test_acc_1.png\" alt=\"Test Acc\" width=\"450\"/>\n",
    "<img src=\"f1_score_1.png\" alt=\"F1 Score\" width=\"450\"/>\n",
    "<img src=\"confusion_matrix_1.png\" alt=\"Confusion Matrix\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Qn. What are the spatial dimensions of image after each layer/block? What are these dimensions, in the layer just before average pooling?**\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "- We can use the ``torchinfo`` package to get this information.\n",
    "\n",
    "- The input spatial dimension (36, 36) gets reduced to (18, 18) after the first convolution. Maxpool further reduces it to (9, 9).\n",
    "\n",
    "- The sequence of convolutional blocks successively reduce this to half, giving 512 (2, 2) activation maps.\n",
    "\n",
    "- The average pool and (flattening) converts this to a 512 length vector.\n",
    "\n",
    "```\n",
    "===================================================================================================================\n",
    "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #\n",
    "===================================================================================================================\n",
    "ResNet                                   [1, 3, 36, 36]            [1, 1000]                 --\n",
    "├─Conv2d: 1-1                            [1, 3, 36, 36]            [1, 64, 18, 18]           9,408\n",
    "├─BatchNorm2d: 1-2                       [1, 64, 18, 18]           [1, 64, 18, 18]           128\n",
    "├─ReLU: 1-3                              [1, 64, 18, 18]           [1, 64, 18, 18]           --\n",
    "├─MaxPool2d: 1-4                         [1, 64, 18, 18]           [1, 64, 9, 9]             --\n",
    "├─Sequential: 1-5                        [1, 64, 9, 9]             [1, 64, 9, 9]             --\n",
    "│    └─BasicBlock: 2-1                   [1, 64, 9, 9]             [1, 64, 9, 9]             --\n",
    "│    │    └─Conv2d: 3-1                  [1, 64, 9, 9]             [1, 64, 9, 9]             36,864\n",
    "│    │    └─BatchNorm2d: 3-2             [1, 64, 9, 9]             [1, 64, 9, 9]             128\n",
    "│    │    └─ReLU: 3-3                    [1, 64, 9, 9]             [1, 64, 9, 9]             --\n",
    "│    │    └─Conv2d: 3-4                  [1, 64, 9, 9]             [1, 64, 9, 9]             36,864\n",
    "│    │    └─BatchNorm2d: 3-5             [1, 64, 9, 9]             [1, 64, 9, 9]             128\n",
    "│    │    └─ReLU: 3-6                    [1, 64, 9, 9]             [1, 64, 9, 9]             --\n",
    "│    └─BasicBlock: 2-2                   [1, 64, 9, 9]             [1, 64, 9, 9]             --\n",
    "│    │    └─Conv2d: 3-7                  [1, 64, 9, 9]             [1, 64, 9, 9]             36,864\n",
    "│    │    └─BatchNorm2d: 3-8             [1, 64, 9, 9]             [1, 64, 9, 9]             128\n",
    "│    │    └─ReLU: 3-9                    [1, 64, 9, 9]             [1, 64, 9, 9]             --\n",
    "│    │    └─Conv2d: 3-10                 [1, 64, 9, 9]             [1, 64, 9, 9]             36,864\n",
    "│    │    └─BatchNorm2d: 3-11            [1, 64, 9, 9]             [1, 64, 9, 9]             128\n",
    "│    │    └─ReLU: 3-12                   [1, 64, 9, 9]             [1, 64, 9, 9]             --\n",
    "├─Sequential: 1-6                        [1, 64, 9, 9]             [1, 128, 5, 5]            --\n",
    "│    └─BasicBlock: 2-3                   [1, 64, 9, 9]             [1, 128, 5, 5]            --\n",
    "│    │    └─Conv2d: 3-13                 [1, 64, 9, 9]             [1, 128, 5, 5]            73,728\n",
    "│    │    └─BatchNorm2d: 3-14            [1, 128, 5, 5]            [1, 128, 5, 5]            256\n",
    "│    │    └─ReLU: 3-15                   [1, 128, 5, 5]            [1, 128, 5, 5]            --\n",
    "│    │    └─Conv2d: 3-16                 [1, 128, 5, 5]            [1, 128, 5, 5]            147,456\n",
    "│    │    └─BatchNorm2d: 3-17            [1, 128, 5, 5]            [1, 128, 5, 5]            256\n",
    "│    │    └─Sequential: 3-18             [1, 64, 9, 9]             [1, 128, 5, 5]            8,448\n",
    "│    │    └─ReLU: 3-19                   [1, 128, 5, 5]            [1, 128, 5, 5]            --\n",
    "│    └─BasicBlock: 2-4                   [1, 128, 5, 5]            [1, 128, 5, 5]            --\n",
    "│    │    └─Conv2d: 3-20                 [1, 128, 5, 5]            [1, 128, 5, 5]            147,456\n",
    "│    │    └─BatchNorm2d: 3-21            [1, 128, 5, 5]            [1, 128, 5, 5]            256\n",
    "│    │    └─ReLU: 3-22                   [1, 128, 5, 5]            [1, 128, 5, 5]            --\n",
    "│    │    └─Conv2d: 3-23                 [1, 128, 5, 5]            [1, 128, 5, 5]            147,456\n",
    "│    │    └─BatchNorm2d: 3-24            [1, 128, 5, 5]            [1, 128, 5, 5]            256\n",
    "│    │    └─ReLU: 3-25                   [1, 128, 5, 5]            [1, 128, 5, 5]            --\n",
    "├─Sequential: 1-7                        [1, 128, 5, 5]            [1, 256, 3, 3]            --\n",
    "│    └─BasicBlock: 2-5                   [1, 128, 5, 5]            [1, 256, 3, 3]            --\n",
    "│    │    └─Conv2d: 3-26                 [1, 128, 5, 5]            [1, 256, 3, 3]            294,912\n",
    "│    │    └─BatchNorm2d: 3-27            [1, 256, 3, 3]            [1, 256, 3, 3]            512\n",
    "│    │    └─ReLU: 3-28                   [1, 256, 3, 3]            [1, 256, 3, 3]            --\n",
    "│    │    └─Conv2d: 3-29                 [1, 256, 3, 3]            [1, 256, 3, 3]            589,824\n",
    "│    │    └─BatchNorm2d: 3-30            [1, 256, 3, 3]            [1, 256, 3, 3]            512\n",
    "│    │    └─Sequential: 3-31             [1, 128, 5, 5]            [1, 256, 3, 3]            33,280\n",
    "│    │    └─ReLU: 3-32                   [1, 256, 3, 3]            [1, 256, 3, 3]            --\n",
    "│    └─BasicBlock: 2-6                   [1, 256, 3, 3]            [1, 256, 3, 3]            --\n",
    "│    │    └─Conv2d: 3-33                 [1, 256, 3, 3]            [1, 256, 3, 3]            589,824\n",
    "│    │    └─BatchNorm2d: 3-34            [1, 256, 3, 3]            [1, 256, 3, 3]            512\n",
    "│    │    └─ReLU: 3-35                   [1, 256, 3, 3]            [1, 256, 3, 3]            --\n",
    "│    │    └─Conv2d: 3-36                 [1, 256, 3, 3]            [1, 256, 3, 3]            589,824\n",
    "│    │    └─BatchNorm2d: 3-37            [1, 256, 3, 3]            [1, 256, 3, 3]            512\n",
    "│    │    └─ReLU: 3-38                   [1, 256, 3, 3]            [1, 256, 3, 3]            --\n",
    "├─Sequential: 1-8                        [1, 256, 3, 3]            [1, 512, 2, 2]            --\n",
    "│    └─BasicBlock: 2-7                   [1, 256, 3, 3]            [1, 512, 2, 2]            --\n",
    "│    │    └─Conv2d: 3-39                 [1, 256, 3, 3]            [1, 512, 2, 2]            1,179,648\n",
    "│    │    └─BatchNorm2d: 3-40            [1, 512, 2, 2]            [1, 512, 2, 2]            1,024\n",
    "│    │    └─ReLU: 3-41                   [1, 512, 2, 2]            [1, 512, 2, 2]            --\n",
    "│    │    └─Conv2d: 3-42                 [1, 512, 2, 2]            [1, 512, 2, 2]            2,359,296\n",
    "│    │    └─BatchNorm2d: 3-43            [1, 512, 2, 2]            [1, 512, 2, 2]            1,024\n",
    "│    │    └─Sequential: 3-44             [1, 256, 3, 3]            [1, 512, 2, 2]            132,096\n",
    "│    │    └─ReLU: 3-45                   [1, 512, 2, 2]            [1, 512, 2, 2]            --\n",
    "│    └─BasicBlock: 2-8                   [1, 512, 2, 2]            [1, 512, 2, 2]            --\n",
    "│    │    └─Conv2d: 3-46                 [1, 512, 2, 2]            [1, 512, 2, 2]            2,359,296\n",
    "│    │    └─BatchNorm2d: 3-47            [1, 512, 2, 2]            [1, 512, 2, 2]            1,024\n",
    "│    │    └─ReLU: 3-48                   [1, 512, 2, 2]            [1, 512, 2, 2]            --\n",
    "│    │    └─Conv2d: 3-49                 [1, 512, 2, 2]            [1, 512, 2, 2]            2,359,296\n",
    "│    │    └─BatchNorm2d: 3-50            [1, 512, 2, 2]            [1, 512, 2, 2]            1,024\n",
    "│    │    └─ReLU: 3-51                   [1, 512, 2, 2]            [1, 512, 2, 2]            --\n",
    "├─AdaptiveAvgPool2d: 1-9                 [1, 512, 2, 2]            [1, 512, 1, 1]            --\n",
    "├─Linear: 1-10                           [1, 512]                  [1, 1000]                 513,000\n",
    "===================================================================================================================\n",
    "Total params: 11,689,512\n",
    "Trainable params: 11,689,512\n",
    "Non-trainable params: 0\n",
    "Total mult-adds (Units.MEGABYTES): 81.05\n",
    "===================================================================================================================\n",
    "Input size (MB): 0.02\n",
    "Forward/backward pass size (MB): 1.28\n",
    "Params size (MB): 46.76\n",
    "Estimated Total Size (MB): 48.05\n",
    "===================================================================================================================\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training ResNet on resized images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform_224 = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation((-7,7)),\n",
    "    transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),\n",
    "    transforms.Normalize((0.491, 0.482, 0.446), (0.247, 0.243, 0.261)),\n",
    "])\n",
    "test_transform_224 = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Normalize((0.491, 0.482, 0.446), (0.247, 0.243, 0.261)),\n",
    "])\n",
    "\n",
    "train_dataset_224 = CustomDataset(train_data, train_labels, transform=train_transform_224)\n",
    "test_dataset_224 = CustomDataset(test_data, test_labels, transform=test_transform_224)\n",
    "\n",
    "train_loader_224 = DataLoader(train_dataset_224, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader_224 = DataLoader(test_dataset_224, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_224 = resnet18(num_classes=10)\n",
    "train_model(model_224, train_loader_224, test_loader_224, 'scratch_224')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_224 = resnet18(weights='DEFAULT')\n",
    "pretrained_model_224.fc = nn.Linear(512, 10)\n",
    "train_model(pretrained_model_224, train_loader_224, test_loader_224, 'pretrained_224')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"train_loss_2.png\" alt=\"Train Loss\" width=\"450\"/>\n",
    "<img src=\"train_acc_2.png\" alt=\"Train Acc\" width=\"450\"/>\n",
    "<img src=\"test_acc_2.png\" alt=\"Test Acc\" width=\"450\"/>\n",
    "<img src=\"f1_score_2.png\" alt=\"F1 Score\" width=\"450\"/>\n",
    "<img src=\"confusion_matrix_2.png\" alt=\"Confusion Matrix\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Qn. Better accuracy may come at cost. What changed/degraded from the previous set up?**\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "- An input of large spatial dimension leads to larger activation maps across the network.\n",
    "\n",
    "- This makes the forward and backward passes slower, since the time complexity of convolution is proportional to the input dimension.\n",
    "\n",
    "- In our experimentation, we found the model training process to be ~5 times slower.\n",
    "\n",
    "- We can expect similar (but not exactly the same) slowdown during inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modifying the architecture of ResNet18 to suit the given dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Modifying ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_model_1 = resnet18(num_classes=10)\n",
    "modified_model_1.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=1, padding=3, bias=False)\n",
    "train_model(modified_model_1, train_loader, test_loader, 'modified_scratch_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_model_2 = resnet18(num_classes=10)\n",
    "modified_model_2.conv1 = nn.Conv2d(3, 64, kernel_size=5, stride=1, padding=2, bias=False)\n",
    "train_model(modified_model_2, train_loader, test_loader, 'modified_scratch_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_model_3 = resnet18(num_classes=10)\n",
    "modified_model_3.maxpool = nn.Identity()\n",
    "train_model(modified_model_3, train_loader, test_loader, 'modified_scratch_3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"train_loss_3a.png\" alt=\"Train Loss\" width=\"450\"/>\n",
    "<img src=\"train_acc_3a.png\" alt=\"Train Acc\" width=\"450\"/>\n",
    "<img src=\"test_acc_3a.png\" alt=\"Test Acc\" width=\"450\"/>\n",
    "<img src=\"f1_score_3a.png\" alt=\"F1 Score\" width=\"450\"/>\n",
    "<img src=\"confusion_matrix_3a.png\" alt=\"Confusion Matrix\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Modifying Pretrained ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_1 = resnet18(weights='DEFAULT')\n",
    "pretrained_model_1.fc = nn.Linear(512, 10)\n",
    "pretrained_model_1.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=1, padding=3, bias=False)\n",
    "train_model(pretrained_model_1, train_loader, test_loader, 'modified_pretrained_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_2 = resnet18(weights='DEFAULT')\n",
    "pretrained_model_2.fc = nn.Linear(512, 10)\n",
    "pretrained_model_2.conv1 = nn.Conv2d(3, 64, kernel_size=5, stride=1, padding=2, bias=False)\n",
    "train_model(pretrained_model_2, train_loader, test_loader, 'modified_pretrained_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_3 = resnet18(weights='DEFAULT')\n",
    "pretrained_model_3.fc = nn.Linear(512, 10)\n",
    "pretrained_model_3.maxpool = nn.Identity()\n",
    "train_model(pretrained_model_3, train_loader, test_loader, 'modified_pretrained_3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"train_loss_3b.png\" alt=\"Train Loss\" width=\"450\"/>\n",
    "<img src=\"train_acc_3b.png\" alt=\"Train Acc\" width=\"450\"/>\n",
    "<img src=\"test_acc_3b.png\" alt=\"Test Acc\" width=\"450\"/>\n",
    "<img src=\"f1_score_3b.png\" alt=\"F1 Score\" width=\"450\"/>\n",
    "<img src=\"confusion_matrix_3b.png\" alt=\"Confusion Matrix\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Qn. In the case of the pretrained model, the first layer needs to be initialized from scratch, while the other layers have weights of the pretrained model. Would such an initialization (with different distributions in different layers) be a problem and make the model learn worse, or does it not affect the training significantly?**\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "- We start by observing that the modified pretrained models give better results than the pretrained models.\n",
    "\n",
    "- It has been noted that training on natural images tends to produce task-agnostic features (see https://arxiv.org/abs/1411.1792).\n",
    "\n",
    "- Learning such general-purpose features from scratch isn't difficult on re-initialization.\n",
    "\n",
    "- Presence of learned weights in other layers only help stabilize the learning process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Qn. Compare all the different aspects of the trained models. Draw comparisions between pretrained versus non-pretrained, effects of the size of the image, the kernel size, etc.**\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "- Pretraining: The pretrained model achieves better results. Exposure to a much more diverse ImageNet dataset must have improved its generalization capability.\n",
    "\n",
    "- Image Size: The best metrics were obtained for models trained on $(224, 224)$ images. As pointed out in the question, the model is better suited for this dimension. On the other hand, downsampling to $(9, 9)$ in just two layers can lead to a significant loss of information. Representing objects like truck, ship, etc. may not be best suited for such a small dimension learned via a couple of transformations.\n",
    "\n",
    "- Kernel Size: Conflicting results were obtained for the randomly initialized and pretrained models, about the use of $(5, 5)$ or $(7, 7)$ kernel.\n",
    "\n",
    "- Kernel Stride: The default value of $stride = 2$ leads to downsampling from $(36, 36)$ to $(18, 18)$. An improvement in metrics was observed for both the models on changing the $stride$ to 1.\n",
    "\n",
    "- Pooling: The maxpool layer in the early stage of the model leads to downsampling from $(18, 18)$ to $(9, 9)$. Since we would like to have a higher dimension representation, replacing the maxpool layer with an identity function would be suitable. This results in an improvement in metrics for both the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Qn. Additionally, look at the F1 score and confusion matrices as accuracy is not always the perfect measure.**\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "- See the respective sections or this [sheet](wandb_export.csv) for the metrics.\n",
    "\n",
    "- No case was found in this experiment, where a model with higher accuracy had a lower F1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Qn. Explain why you think those differences arise.**\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "- The difference between accuracy and F1 score commonly arises because of skew in distribution. Since each loss or error is given equal weightage regardless of its type, this can create large gaps in line with the skew in data.\n",
    "\n",
    "- For example, when the negative samples outnumber the positives (sparsity), the baseline accuracy for always predicting negative increases. The model can thus learn to make skewed predictions to maximize its accuracy over skewed datasets.\n",
    "\n",
    "- A counter example would be where model predicts the positive and negative class with equal probability. Indeed, when $TN = TP$, the F1 score is equal to the accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iiit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
